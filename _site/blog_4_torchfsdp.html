<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>blog_4_torchfsdp | Xiaotian Han | Case Western Reserve University</title>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <meta name="description" content="Xiaotian Han">
    <meta name="keywords" content="xiaotian han, han xiaotian, xiaotianhan, hanxiaotian, xiaotian, case western reserve university">


    <meta property="og:type" content="website">
    <meta property="og:title" content="Xiaotian Han | Case Western Reserve University">
    <meta property="og:url" content="https://ahxt.github.io/blog_4_torchfsdp.html">
    <meta property="og:site_name" content="Xiaotian Han | Case Western Reserve University">
    <meta property="og:description" content="Xiaotian Han is an assistant professor in the Department of Computer and Data Sciences at Case Western Reserve University start form Fall 2024. Previously, He obtained my CS Ph.D. at Texas A&M University. His research interests lie in the general area of artifiicial intelligence, machine learning and data science, and recently Large Language Models (LLM).">
    <meta property="og:locale" content="default">
    <meta property="og:image" content="./files/xt.png">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Xiaotian Han | Case Western Reserve University">
    <meta name="twitter:description" content="Xiaotian Han is an assistant professor in the Department of Computer and Data Sciences at Case Western Reserve University start form Fall 2024. Previously, He obtained my CS Ph.D. at Texas A&M University. His research interests lie in the general area of artifiicial intelligence, machine learning and data science, and recently Large Language Models (LLM).">
    <meta name="twitter:image" content="./files/xt.png">

    <link rel="canonical" href="https://ahxt.github.io/blog_4_torchfsdp.html"/>
    <link rel="icon" href="../files/favicon.ico" type="image/x-icon">
    <meta name="theme-color" content="#ffffff">
    <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="../assets/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">
    
    <script src="../assets/js/github-stars.js"></script>
    <script type="text/javascript" src="../assets/js/jquery.js"></script>
    <script src="../assets/js/favicon-switcher.js" type="application/javascript"></script>
    
   


  </head>
  <body>
    
    <div class="topnav">
      <a class="name">Xiaotian Han</a>
      <div id="myLinks">
        
          <a class="normal" href="/">Home</a>
        
          <a class="normal" href="/#publications">Publications</a>
        
          <a class="normal" href="/teaching.html">Teaching</a>
        
          <a class="normal" href="/group.html">Group</a>
        
          <a class="normal" href="/blog.html">Blog</a>
        
      </div>
    </div>
    

      
    </div>
    

    <script src="../assets/js/vanilla-back-to-top.min.js"></script>
    <script>addBackToTop({
        backgroundColor: '#fff',
        innerHTML: 'Back to Top',
        textColor: '#333'
      })
    </script>
    <style>
        #back-to-top {
          border: 1px solid #ccc;
          border-radius: 4px;
          font-size: 15px;
          width: 100px;
          text-align: center;
          line-height: 30px;
          height: 30px;
        }
    </style>
    
    <div class="wrapper">
      <sectionb>
        <h1 id="litellama-a-lightweight-transformer-for-efficient-language-modeling">LiteLlama: A Lightweight Transformer for Efficient Language Modeling</h1>

<ul>
  <li>Xiaotian Han</li>
  <li>01/25/2024</li>
</ul>

<h2 id="tldr">TL;DR</h2>
<p>We propose LiteLlama, a lightweight transformer model for efficient language modeling. LiteLlama is designed to be more efficient than the original transformer model while maintaining competitive performance. We achieve this by reducing the model size and the number of parameters. We also introduce a new position embedding method that is more efficient than the original method. We evaluate LiteLlama on the WikiText-103 dataset and show that it outperforms the original transformer model in terms of speed and memory usage while maintaining competitive performance.</p>

<h3 id="introduction">Introduction</h3>
<p>In this blog post, we introduce LiteLlama, a lightweight transformer model for efficient language modeling. LiteLlama is designed to be more efficient than the original transformer model while maintaining competitive performance. We achieve this by reducing the model size and the number of parameters. We also introduce a new position embedding method that is more efficient than the original method. We evaluate LiteLlama on the WikiText-103 dataset and show that it outperforms the original transformer model in terms of speed and memory usage while maintaining competitive performance.</p>

<div class="language-python highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">torch</span>
<span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">torch.nn</span> <span style="color:#080;font-weight:bold">as</span> nn
<span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">torch.optim</span> <span style="color:#080;font-weight:bold">as</span> optim
<span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">torch.nn.functional</span> <span style="color:#080;font-weight:bold">as</span> F

<span style="color:#080;font-weight:bold">class</span> <span style="color:#B06;font-weight:bold">LiteLlama</span>(nn.Module):
    <span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">__init__</span>(<span style="color:#069">self</span>, vocab_size, embedding_dim, hidden_dim, num_layers):
        <span style="color:#369;font-weight:bold">super</span>(LiteLlama, <span style="color:#069">self</span>).__init__()
        <span style="color:#069">self</span>.embedding = nn.Embedding(vocab_size, embedding_dim)

        <span style="color:#069">self</span>.encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(embedding_dim, num_heads=<span style="color:#00D">8</span>, dim_feedforward=hidden_dim),
            num_layers=num_layers
        )
</pre></div>
</div>
</div>

<h3 id="related-work">Related Work</h3>

\[x, \mathbb{X},  \mathbf{X}\]

\[\sum_w \frac{1}{\sqrt{d}} \exp\left(\frac{1}{\sqrt{d}}\right)\]

<h2 id="litellama-architecture">LiteLlama Architecture</h2>

<h3 id="model-overview">Model Overview</h3>
<p>asdfad</p>

<h3 id="position-embedding">Position Embedding</h3>

<h2 id="training-details">Training Details</h2>


      </sectionb>
    </div>

    <script src="/assets/js/scale.fix.js"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          processEscapes: true
        }
      });
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>
    
  </body>
</html>
